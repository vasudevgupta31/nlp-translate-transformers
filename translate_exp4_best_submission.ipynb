{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9eafe769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best submission generated via this: submission_8_exp41_maxckp_genv2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53814356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "from src.tokenizers.eng import EnglishTokenizer\n",
    "from src.tokenizers.indic import IndicTokenizer\n",
    "from src.components import TransformerMT as selftx\n",
    "from src.torchlayers import TransformerMT as torchtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58a44b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(model, eng_tokenizer, indic_tokenizer, english_texts, device='cuda', verbose=False):\n",
    "    \n",
    "    # all texts to sequences at once\n",
    "    english_ids = eng_tokenizer.texts_to_sequences(english_texts)\n",
    "    english_tensor = torch.tensor(english_ids, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # generate translations for the entire batch from model.generate\n",
    "        translation_ids = model.generatev2(english_tensor, max_length=30, temperature=0.0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Batch size: {len(english_texts)}\")\n",
    "        print(f\"Generated shape: {translation_ids.shape}\")\n",
    "\n",
    "    # decode from indic_detokenizer\n",
    "    translation_array = translation_ids.cpu().numpy()\n",
    "    indic_texts = indic_tokenizer.sequences_to_texts(translation_array)\n",
    "    \n",
    "    return indic_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "024781ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open(os.path.join(\"data\", \"raw\", \"val_data1.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df2c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c90a6eb",
   "metadata": {},
   "source": [
    "### ENG 2 HINDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3b88aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    SRC_VOCAB_SIZE: int = 30_000                      # source vocabulary size\n",
    "    TGT_VOCAB_SIZE: int = 30_000                      # target vocabulary size\n",
    "    SRC_MAX_LENGTH: int = 256                         # max sequence length source lang\n",
    "    TGT_MAX_LENGTH: int = 256                         # max sequence length target lang\n",
    "    D_MODEL: int = 128                                # embedding dimension\n",
    "    N_HEADS: int = 8                                  # number of heads in attention\n",
    "    N_LAYERS: int = 6                                 # number of transformer blocks\n",
    "    D_FF: int = 128 * 4                               # dimension of feedforward (4x of embedding dims)\n",
    "    MAX_SEQ_LEN: int = 256\n",
    "    DROPOUT: float = 0.1\n",
    "    BATCH_SIZE: int = 32\n",
    "    EVAL_STEPS: int = 100\n",
    "    EPOCHS: int = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbc402f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_checkpoint_path = os.path.join(\"checkpoints\", \"eng_hindi\", \"exp4.1-eng-hindi-transformer-built-in\")\n",
    "checkpoint = torch.load(os.path.join(hindi_checkpoint_path, \"tx_epoch_20_step_45000.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "687909e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['step', 'epoch', 'model_state_dict', 'optimizer_state_dict', 'loss', 'config', 'tr_lossi', 'val_lossi', 'eng_tokenizer', 'indic_tokenizer', 'model_config'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d10e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate ENGLISH tokenizer\n",
    "eng_tok = EnglishTokenizer(checkpoint['eng_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['eng_tokenizer']['max_length'])\n",
    "eng_tok.word2idx = checkpoint['eng_tokenizer']['word2idx']\n",
    "eng_tok.idx2word = checkpoint['eng_tokenizer']['idx2word']\n",
    "eng_tok.vocab_size = checkpoint['eng_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e220044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate INDIC tokenizer\n",
    "indic_tok = IndicTokenizer(checkpoint['indic_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['indic_tokenizer']['max_length'])\n",
    "indic_tok.word2idx = checkpoint['indic_tokenizer']['word2idx']\n",
    "indic_tok.idx2word = checkpoint['indic_tokenizer']['idx2word']\n",
    "indic_tok.vocab_size = checkpoint['indic_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfcf48a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = checkpoint['model_config']\n",
    "model = torchtx(**model_config)\n",
    "model.to('cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27c74321",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_batch(model, eng_tok, indic_tok, english_texts=[\"Hi how are you\"] , device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "088965c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['हाय आप कैसे हैं']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c7bf9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 11543\n",
      "Processing in batches of 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████| 361/361 [03:13<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "hindi_output = pd.DataFrame()\n",
    "ids = []\n",
    "texts = []\n",
    "for id_, entry in test_data['English-Hindi']['Validation'].items():\n",
    "    ids.append(id_)\n",
    "    texts.append(entry['source'])\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "print(f\"Processing in batches of {32}\")\n",
    "\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(texts), 32), desc=\"Processing batches\"):\n",
    "    batch_texts = texts[i:i+32]\n",
    "    batch_translations = translate_batch(model, eng_tok, indic_tok, batch_texts, device='cuda')\n",
    "    all_translations.extend(batch_translations)\n",
    "\n",
    "# gather in df\n",
    "hindi_output['ID'] = ids\n",
    "hindi_output['Translation'] = all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78134ced",
   "metadata": {},
   "source": [
    "### ENG 2 BENGALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69ccbd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    SRC_VOCAB_SIZE: int = 30_000                      # source vocabulary size\n",
    "    TGT_VOCAB_SIZE: int = 30_000                      # target vocabulary size\n",
    "    SRC_MAX_LENGTH: int = 256                         # max sequence length source lang\n",
    "    TGT_MAX_LENGTH: int = 256                         # max sequence length target lang\n",
    "    D_MODEL: int = 128                                # embedding dimension\n",
    "    N_HEADS: int = 4                                  # number of heads in attention\n",
    "    N_LAYERS: int = 6                                 # number of transformer blocks\n",
    "    D_FF: int = 128 * 4                               # dimension of feedforward (4x of embedding dims)\n",
    "    MAX_SEQ_LEN: int = 256\n",
    "    DROPOUT: float = 0.1\n",
    "    BATCH_SIZE: int = 32\n",
    "    EVAL_STEPS: int = 500\n",
    "    EPOCHS: int = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94ab8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "bengali_checkpoint_path = os.path.join(\"checkpoints\", \"eng_bengali\", \"exp4.1-eng-bengali-transformer-built-in\")\n",
    "checkpoint = torch.load(os.path.join(bengali_checkpoint_path, \"tx_epoch_13_step_25000.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b01e6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate ENGLISH tokenizer\n",
    "eng_tok = EnglishTokenizer(checkpoint['eng_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['eng_tokenizer']['max_length'])\n",
    "eng_tok.word2idx = checkpoint['eng_tokenizer']['word2idx']\n",
    "eng_tok.idx2word = checkpoint['eng_tokenizer']['idx2word']\n",
    "eng_tok.vocab_size = checkpoint['eng_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4083fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate INDIC tokenizer\n",
    "indic_tok = IndicTokenizer(checkpoint['indic_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['indic_tokenizer']['max_length'])\n",
    "indic_tok.word2idx = checkpoint['indic_tokenizer']['word2idx']\n",
    "indic_tok.idx2word = checkpoint['indic_tokenizer']['idx2word']\n",
    "indic_tok.vocab_size = checkpoint['indic_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c37c77af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = checkpoint['model_config']\n",
    "model = torchtx(**model_config)\n",
    "model.to('cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49837186",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_batch(model, eng_tok, indic_tok, english_texts=[\"Hi how are you?\"] , device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "212429e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['হাই আপনি কিভাবে কত করছেন?']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d04575a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 9836\n",
      "Processing in batches of 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████| 308/308 [01:49<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "bengali_output = pd.DataFrame()\n",
    "ids = []\n",
    "texts = []\n",
    "for id_, entry in test_data['English-Bengali']['Validation'].items():\n",
    "    ids.append(id_)\n",
    "    texts.append(entry['source'])\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "print(f\"Processing in batches of {32}\")\n",
    "\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(texts), 32), desc=\"Processing batches\"):\n",
    "    batch_texts = texts[i:i+32]\n",
    "    batch_translations = translate_batch(\n",
    "        model, eng_tok, indic_tok, batch_texts, device='cuda'\n",
    "    )\n",
    "    all_translations.extend(batch_translations)\n",
    "\n",
    "\n",
    "bengali_output['ID'] = ids\n",
    "bengali_output['Translation'] = all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6037c0f",
   "metadata": {},
   "source": [
    "## Final output for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11c8c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1939e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([bengali_output, hindi_output]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0c79c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['Translation'] = output['Translation'].str.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0848bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\n",
    "    \"answers/val/answer41_generatev2.csv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=True,\n",
    "    quoting=csv.QUOTE_ALL,\n",
    "    lineterminator=\"\\n\",\n",
    "    doublequote=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73447c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_csv(\"answers/val/answer1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "38bb2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = \"answers/val/answer1.csv\"\n",
    "# with open(answer, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f, delimiter=\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "#     writer.writerow([\"ID\", \"Translation\"])  # header\n",
    "#     for i in range(output.shape[0]):\n",
    "#         writer.writerow([output[\"ID\"][i], output[\"Translation\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec7560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fac4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2ab9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34aaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df7de70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1d973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
