{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a59ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92c5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best submission generated via this notebook: \n",
    "# dev1: submission_7_exp41_max_ckp.zip            (358645)\n",
    "# dev2: submission_8_exp41_maxckp_genv2.zip       (358690)\n",
    "\n",
    "# test1: submission_3_exp4dot1_max_ckp.zip        (359202)\n",
    "# test2: submission_4_exp4dot1_max_ckp_genv2.zip  (359211) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b88cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "from src.tokenizers.eng import EnglishTokenizer\n",
    "from src.tokenizers.indic import IndicTokenizer\n",
    "from src.components import TransformerMT as selftx\n",
    "from src.torchlayers import TransformerMT as torchtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31a6a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(model, eng_tokenizer, indic_tokenizer, english_texts, device='cuda', verbose=False):\n",
    "    \n",
    "    # all texts to sequences at once\n",
    "    english_ids = eng_tokenizer.texts_to_sequences(english_texts)\n",
    "    english_tensor = torch.tensor(english_ids, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # generate translations for the entire batch from model.generate\n",
    "        translation_ids = model.generatev2(english_tensor, max_length=30, temperature=0.8)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Batch size: {len(english_texts)}\")\n",
    "        print(f\"Generated shape: {translation_ids.shape}\")\n",
    "\n",
    "    # decode from indic_detokenizer\n",
    "    translation_array = translation_ids.cpu().numpy()\n",
    "    indic_texts = indic_tokenizer.sequences_to_texts(translation_array)\n",
    "    \n",
    "    return indic_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd8feb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train phase\n",
    "# test_data = json.load(open(os.path.join(\"data\", \"raw\", \"val_data1.json\")))\n",
    "# key = 'Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4498a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train phase\n",
    "test_data = json.load(open(os.path.join(\"data\", \"raw\", \"test_data1_final.json\")))\n",
    "key = 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7beae17",
   "metadata": {},
   "source": [
    "### ENG 2 HINDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74c9071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    SRC_VOCAB_SIZE: int = 30_000                      # source vocabulary size\n",
    "    TGT_VOCAB_SIZE: int = 30_000                      # target vocabulary size\n",
    "    SRC_MAX_LENGTH: int = 256                         # max sequence length source lang\n",
    "    TGT_MAX_LENGTH: int = 256                         # max sequence length target lang\n",
    "    D_MODEL: int = 128                                # embedding dimension\n",
    "    N_HEADS: int = 8                                  # number of heads in attention\n",
    "    N_LAYERS: int = 6                                 # number of transformer blocks\n",
    "    D_FF: int = 128 * 4                               # dimension of feedforward (4x of embedding dims)\n",
    "    MAX_SEQ_LEN: int = 256\n",
    "    DROPOUT: float = 0.1\n",
    "    BATCH_SIZE: int = 32\n",
    "    EVAL_STEPS: int = 100\n",
    "    EPOCHS: int = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2bf9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_checkpoint_path = os.path.join(\"checkpoints\", \"eng_hindi\", \"exp4.1-eng-hindi-transformer-built-in\")\n",
    "checkpoint = torch.load(os.path.join(hindi_checkpoint_path, \"tx_epoch_21_step_45500.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0052060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['step', 'epoch', 'model_state_dict', 'optimizer_state_dict', 'loss', 'config', 'tr_lossi', 'val_lossi', 'eng_tokenizer', 'indic_tokenizer', 'model_config'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e06dbcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate ENGLISH tokenizer\n",
    "eng_tok = EnglishTokenizer(checkpoint['eng_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['eng_tokenizer']['max_length'])\n",
    "eng_tok.word2idx = checkpoint['eng_tokenizer']['word2idx']\n",
    "eng_tok.idx2word = checkpoint['eng_tokenizer']['idx2word']\n",
    "eng_tok.vocab_size = checkpoint['eng_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6f59aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate INDIC tokenizer\n",
    "indic_tok = IndicTokenizer(checkpoint['indic_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['indic_tokenizer']['max_length'])\n",
    "indic_tok.word2idx = checkpoint['indic_tokenizer']['word2idx']\n",
    "indic_tok.idx2word = checkpoint['indic_tokenizer']['idx2word']\n",
    "indic_tok.vocab_size = checkpoint['indic_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "314a88ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = checkpoint['model_config']\n",
    "model = torchtx(**model_config)\n",
    "model.to('cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37e1ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_batch(model, eng_tok, indic_tok, english_texts=[\"Hi how are you\"] , device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cffe289a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['हाय आप कैसे हैं? RD _ PUNC एम. out करो? 11? अलग हैं!']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db506bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 23085\n",
      "Processing in batches of 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|▌                                                                | 6/722 [00:03<07:32,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), \u001b[32m32\u001b[39m), desc=\u001b[33m\"\u001b[39m\u001b[33mProcessing batches\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     13\u001b[39m     batch_texts = texts[i:i+\u001b[32m32\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     batch_translations = \u001b[43mtranslate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meng_tok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindic_tok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     all_translations.extend(batch_translations)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# gather in df\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtranslate_batch\u001b[39m\u001b[34m(model, eng_tokenizer, indic_tokenizer, english_texts, device, verbose)\u001b[39m\n\u001b[32m      5\u001b[39m english_tensor = torch.tensor(english_ids, device=device)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# generate translations for the entire batch from model.generate\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     translation_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeneratev2\u001b[49m\u001b[43m(\u001b[49m\u001b[43menglish_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(english_texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiments/iitk-nlp/Capstone/src/torchlayers.py:227\u001b[39m, in \u001b[36mTransformerMT.generatev2\u001b[39m\u001b[34m(self, src, max_length, temperature, min_length, repetition_penalty, length_penalty)\u001b[39m\n\u001b[32m    225\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m generated[i]:\n\u001b[32m    226\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m token_counts[i, token] > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m                     logits[i, token] /= repetition_penalty\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# prevent early EOS\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step < min_length:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "hindi_output = pd.DataFrame()\n",
    "ids = []\n",
    "texts = []\n",
    "for id_, entry in test_data['English-Hindi'][key].items():\n",
    "    ids.append(id_)\n",
    "    texts.append(entry['source'])\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "print(f\"Processing in batches of {32}\")\n",
    "\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(texts), 32), desc=\"Processing batches\"):\n",
    "    batch_texts = texts[i:i+32]\n",
    "    batch_translations = translate_batch(model, eng_tok, indic_tok, batch_texts, device='cuda')\n",
    "    all_translations.extend(batch_translations)\n",
    "\n",
    "# gather in df\n",
    "hindi_output['ID'] = ids\n",
    "hindi_output['Translation'] = all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b17c1",
   "metadata": {},
   "source": [
    "### ENG 2 BENGALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b81ac543",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    SRC_VOCAB_SIZE: int = 30_000                      # source vocabulary size\n",
    "    TGT_VOCAB_SIZE: int = 30_000                      # target vocabulary size\n",
    "    SRC_MAX_LENGTH: int = 256                         # max sequence length source lang\n",
    "    TGT_MAX_LENGTH: int = 256                         # max sequence length target lang\n",
    "    D_MODEL: int = 128                                # embedding dimension\n",
    "    N_HEADS: int = 4                                  # number of heads in attention\n",
    "    N_LAYERS: int = 6                                 # number of transformer blocks\n",
    "    D_FF: int = 128 * 4                               # dimension of feedforward (4x of embedding dims)\n",
    "    MAX_SEQ_LEN: int = 256\n",
    "    DROPOUT: float = 0.1\n",
    "    BATCH_SIZE: int = 32\n",
    "    EVAL_STEPS: int = 500\n",
    "    EPOCHS: int = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1b26cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bengali_checkpoint_path = os.path.join(\"checkpoints\", \"eng_bengali\", \"exp4.1-eng-bengali-transformer-built-in\")\n",
    "checkpoint = torch.load(os.path.join(bengali_checkpoint_path, \"tx_epoch_13_step_25000.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ea7f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate ENGLISH tokenizer\n",
    "eng_tok = EnglishTokenizer(checkpoint['eng_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['eng_tokenizer']['max_length'])\n",
    "eng_tok.word2idx = checkpoint['eng_tokenizer']['word2idx']\n",
    "eng_tok.idx2word = checkpoint['eng_tokenizer']['idx2word']\n",
    "eng_tok.vocab_size = checkpoint['eng_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9323eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate INDIC tokenizer\n",
    "indic_tok = IndicTokenizer(checkpoint['indic_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['indic_tokenizer']['max_length'])\n",
    "indic_tok.word2idx = checkpoint['indic_tokenizer']['word2idx']\n",
    "indic_tok.idx2word = checkpoint['indic_tokenizer']['idx2word']\n",
    "indic_tok.vocab_size = checkpoint['indic_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f16957d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = checkpoint['model_config']\n",
    "model = torchtx(**model_config)\n",
    "model.to('cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28e63f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_batch(model, eng_tok, indic_tok, english_texts=[\"Hi how are you?\"] , device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1f3155b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['হাই আপনি কিভাবে কত করছেন? মি? মি? \"?\" তুমি কি তুমি কি তুমি টা পারো']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2228732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 19672\n",
      "Processing in batches of 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████| 615/615 [04:26<00:00,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "bengali_output = pd.DataFrame()\n",
    "ids = []\n",
    "texts = []\n",
    "for id_, entry in test_data['English-Bengali'][key].items():\n",
    "    ids.append(id_)\n",
    "    texts.append(entry['source'])\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "print(f\"Processing in batches of {32}\")\n",
    "\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(texts), 32), desc=\"Processing batches\"):\n",
    "    batch_texts = texts[i:i+32]\n",
    "    batch_translations = translate_batch(\n",
    "        model, eng_tok, indic_tok, batch_texts, device='cuda'\n",
    "    )\n",
    "    all_translations.extend(batch_translations)\n",
    "\n",
    "\n",
    "bengali_output['ID'] = ids\n",
    "bengali_output['Translation'] = all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbacd44",
   "metadata": {},
   "source": [
    "## Final output for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29af107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0e21546",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([bengali_output, hindi_output]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31bff65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['Translation'] = output['Translation'].str.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47f8a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\n",
    "    \"answers/test/answer4dot1genv2.csv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=True,\n",
    "    quoting=csv.QUOTE_ALL,\n",
    "    lineterminator=\"\\n\",\n",
    "    doublequote=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e76eca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_csv(\"answers/val/answer1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f524c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = \"answers/val/answer1.csv\"\n",
    "# with open(answer, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f, delimiter=\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "#     writer.writerow([\"ID\", \"Translation\"])  # header\n",
    "#     for i in range(output.shape[0]):\n",
    "#         writer.writerow([output[\"ID\"][i], output[\"Translation\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe02ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15729f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481240b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaa7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f3faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9349fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72fcb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
