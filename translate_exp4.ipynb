{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6dc701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "from src.tokenizers.eng import EnglishTokenizer\n",
    "from src.tokenizers.indic import IndicTokenizer\n",
    "from src.components import TransformerMT as selftx\n",
    "from src.torchlayers import TransformerMT as torchtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6aee15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(model, eng_tokenizer, indic_tokenizer, english_texts, device='cuda', verbose=False):\n",
    "    \n",
    "    # all texts to sequences at once\n",
    "    english_ids = eng_tokenizer.texts_to_sequences(english_texts)\n",
    "    english_tensor = torch.tensor(english_ids, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # generate translations for the entire batch from model.generate\n",
    "        translation_ids = model.generate(english_tensor, max_length=20, temperature=0.0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Batch size: {len(english_texts)}\")\n",
    "        print(f\"Generated shape: {translation_ids.shape}\")\n",
    "\n",
    "    # decode from indic_detokenizer\n",
    "    translation_array = translation_ids.cpu().numpy()\n",
    "    indic_texts = indic_tokenizer.sequences_to_texts(translation_array)\n",
    "    \n",
    "    return indic_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20eea051",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open(os.path.join(\"data\", \"raw\", \"val_data1.json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f75d9",
   "metadata": {},
   "source": [
    "### ENG 2 HINDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23fc1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    SRC_VOCAB_SIZE: int = 30_000                      # source vocabulary size\n",
    "    TGT_VOCAB_SIZE: int = 30_000                      # target vocabulary size\n",
    "    SRC_MAX_LENGTH: int = 256                         # max sequence length source lang\n",
    "    TGT_MAX_LENGTH: int = 256                         # max sequence length target lang\n",
    "    D_MODEL: int = 128                                # embedding dimension\n",
    "    N_HEADS: int = 4                                  # number of heads in attention\n",
    "    N_LAYERS: int = 6                                 # number of transformer blocks\n",
    "    D_FF: int = 128 * 4                               # dimension of feedforward (4x of embedding dims)\n",
    "    MAX_SEQ_LEN: int = 256\n",
    "    DROPOUT: float = 0.1\n",
    "    BATCH_SIZE: int = 32\n",
    "    EVAL_STEPS: int = 100\n",
    "    EPOCHS: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdadef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_checkpoint_path = os.path.join(\"checkpoints\", \"eng_hindi\", \"exp4-eng-hindi-transformer-built-in\")\n",
    "checkpoint = torch.load(os.path.join(hindi_checkpoint_path, \"tx_epoch_10_step_22500.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8ca725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate ENGLISH tokenizer\n",
    "eng_tok = EnglishTokenizer(checkpoint['eng_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['eng_tokenizer']['max_length'])\n",
    "eng_tok.word2idx = checkpoint['eng_tokenizer']['word2idx']\n",
    "eng_tok.idx2word = checkpoint['eng_tokenizer']['idx2word']\n",
    "eng_tok.vocab_size = checkpoint['eng_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6500edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate INDIC tokenizer\n",
    "indic_tok = IndicTokenizer(checkpoint['indic_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['indic_tokenizer']['max_length'])\n",
    "indic_tok.word2idx = checkpoint['indic_tokenizer']['word2idx']\n",
    "indic_tok.idx2word = checkpoint['indic_tokenizer']['idx2word']\n",
    "indic_tok.vocab_size = checkpoint['indic_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85bca3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = checkpoint['model_config']\n",
    "model = torchtx(**model_config)\n",
    "model.to('cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2125b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/decision/anaconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    }
   ],
   "source": [
    "translation = translate_batch(model, eng_tok, indic_tok, english_texts=[\"Hi\"] , device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6003f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 11543\n",
      "Processing in batches of 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|████████████████████████████████████████████████████████████████████████████| 361/361 [00:26<00:00, 13.62it/s]\n"
     ]
    }
   ],
   "source": [
    "hindi_output = pd.DataFrame()\n",
    "ids = []\n",
    "texts = []\n",
    "for id_, entry in test_data['English-Hindi']['Validation'].items():\n",
    "    ids.append(id_)\n",
    "    texts.append(entry['source'])\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "print(f\"Processing in batches of {32}\")\n",
    "\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(texts), 32), desc=\"Processing batches\"):\n",
    "    batch_texts = texts[i:i+32]\n",
    "    batch_translations = translate_batch(model, eng_tok, indic_tok, batch_texts, device='cuda')\n",
    "    all_translations.extend(batch_translations)\n",
    "\n",
    "# gather in df\n",
    "hindi_output['ID'] = ids\n",
    "hindi_output['Translation'] = all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14005228",
   "metadata": {},
   "source": [
    "### ENG 2 BENGALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f7ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    SRC_VOCAB_SIZE: int = 30_000                      # source vocabulary size\n",
    "    TGT_VOCAB_SIZE: int = 30_000                      # target vocabulary size\n",
    "    SRC_MAX_LENGTH: int = 256                         # max sequence length source lang\n",
    "    TGT_MAX_LENGTH: int = 256                         # max sequence length target lang\n",
    "    D_MODEL: int = 128                                # embedding dimension\n",
    "    N_HEADS: int = 4                                  # number of heads in attention\n",
    "    N_LAYERS: int = 6                                 # number of transformer blocks\n",
    "    D_FF: int = 128 * 4                               # dimension of feedforward (4x of embedding dims)\n",
    "    MAX_SEQ_LEN: int = 256\n",
    "    DROPOUT: float = 0.1\n",
    "    BATCH_SIZE: int = 32\n",
    "    EVAL_STEPS: int = 100\n",
    "    EPOCHS: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96fd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bengali_checkpoint_path = os.path.join(\"checkpoints\", \"eng_bengali\", \"exp4-eng-bengali-transformer-built-in\")\n",
    "checkpoint = torch.load(os.path.join(bengali_checkpoint_path, \"tx_epoch_10_step_19000.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19be58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate ENGLISH tokenizer\n",
    "eng_tok = EnglishTokenizer(checkpoint['eng_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['eng_tokenizer']['max_length'])\n",
    "eng_tok.word2idx = checkpoint['eng_tokenizer']['word2idx']\n",
    "eng_tok.idx2word = checkpoint['eng_tokenizer']['idx2word']\n",
    "eng_tok.vocab_size = checkpoint['eng_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc5c20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate INDIC tokenizer\n",
    "indic_tok = IndicTokenizer(checkpoint['indic_tokenizer']['max_vocab_size'], \n",
    "                           checkpoint['indic_tokenizer']['max_length'])\n",
    "indic_tok.word2idx = checkpoint['indic_tokenizer']['word2idx']\n",
    "indic_tok.idx2word = checkpoint['indic_tokenizer']['idx2word']\n",
    "indic_tok.vocab_size = checkpoint['indic_tokenizer']['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6231053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = checkpoint['model_config']\n",
    "model = torchtx(**model_config)\n",
    "model.to('cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a61a226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_batch(model, eng_tok, indic_tok, english_texts=[\"Hi\"] , device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a069af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 9836\n",
      "Processing in batches of 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|████████████████████████████████████████████████████████████████████████████| 308/308 [00:22<00:00, 13.58it/s]\n"
     ]
    }
   ],
   "source": [
    "bengali_output = pd.DataFrame()\n",
    "ids = []\n",
    "texts = []\n",
    "for id_, entry in test_data['English-Bengali']['Validation'].items():\n",
    "    ids.append(id_)\n",
    "    texts.append(entry['source'])\n",
    "\n",
    "print(f\"Total samples: {len(texts)}\")\n",
    "print(f\"Processing in batches of {32}\")\n",
    "\n",
    "all_translations = []\n",
    "for i in tqdm(range(0, len(texts), 32), desc=\"Processing batches\"):\n",
    "    batch_texts = texts[i:i+32]\n",
    "    batch_translations = translate_batch(\n",
    "        model, eng_tok, indic_tok, batch_texts, device='cuda'\n",
    "    )\n",
    "    all_translations.extend(batch_translations)\n",
    "\n",
    "\n",
    "bengali_output['ID'] = ids\n",
    "bengali_output['Translation'] = all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674b872",
   "metadata": {},
   "source": [
    "## Final output for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a006ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7518b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([bengali_output, hindi_output]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b20ea742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['Translation'] = output['Translation'].str.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb56a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\n",
    "    \"answers/val/answer4.csv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=True,\n",
    "    quoting=csv.QUOTE_ALL,\n",
    "    lineterminator=\"\\n\",\n",
    "    doublequote=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e99b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_csv(\"answers/val/answer1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5386771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = \"answers/val/answer1.csv\"\n",
    "# with open(answer, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f, delimiter=\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "#     writer.writerow([\"ID\", \"Translation\"])  # header\n",
    "#     for i in range(output.shape[0]):\n",
    "#         writer.writerow([output[\"ID\"][i], output[\"Translation\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d08862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b23411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12798de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64706f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec777f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e898a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d66194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
